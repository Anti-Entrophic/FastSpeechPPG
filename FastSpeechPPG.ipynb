{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "04WRc1FTPBcf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Anti-Entrophic/FastSpeechPPG.git\n",
        "%cd /content/FastSpeechPPG/FastSpeech2\n",
        "!pip3 install -r requirements.txt\n",
        "!pip install g2p_en\n",
        "!pip install inflect\n",
        "!pip install librosa\n",
        "!pip install matplotlib\n",
        "!pip install pyworld\n",
        "!pip install tgt\n",
        "!pip install pypinyin==0.39.0\n",
        "!pip install unidecode\n",
        "!pip install --upgrade --no-cache-dir gdown"
      ],
      "metadata": {
        "id": "qOKa8st_ALDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfb5bdee-3365-42cb-e428-2df29f3fd7d6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FastSpeechPPG'...\n",
            "remote: Enumerating objects: 147, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 147 (delta 14), reused 71 (delta 7), pack-reused 52\u001b[K\n",
            "Receiving objects: 100% (147/147), 8.20 MiB | 14.28 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n",
            "/content/FastSpeechPPG/FastSpeech2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting g2p-en==2.1.0\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflect==4.1.0\n",
            "  Downloading inflect-4.1.0-py3-none-any.whl (31 kB)\n",
            "Collecting librosa==0.7.2\n",
            "  Downloading librosa-0.7.2.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting matplotlib==3.2.2\n",
            "  Downloading matplotlib-3.2.2.tar.gz (40.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numba==0.48\n",
            "  Downloading numba-0.48.0.tar.gz (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.19.0\n",
            "  Downloading numpy-1.19.0.zip (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pypinyin==0.39.0\n",
            "  Downloading pypinyin-0.39.0-py2.py3-none-any.whl (780 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.7/780.7 KB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyworld==0.2.10\n",
            "  Downloading pyworld-0.2.10.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.0/74.0 KB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyYAML==5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp39-cp39-manylinux1_x86_64.whl (630 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.1/630.1 KB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==0.23.2\n",
            "  Downloading scikit-learn-0.23.2.tar.gz (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scipy==1.5.0\n",
            "  Downloading scipy-1.5.0.tar.gz (25.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.6/25.6 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting soundfile==0.10.3.post1\n",
            "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
            "Collecting tensorboard==2.2.2\n",
            "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tgt==1.4.4\n",
            "  Downloading tgt-1.4.4.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.7.0 (from versions: 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.7.0\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting g2p_en\n",
            "  Using cached g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.9/dist-packages (from g2p_en) (3.7)\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.9/dist-packages (from g2p_en) (1.22.4)\n",
            "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.9/dist-packages (from g2p_en) (2.1.0)\n",
            "Collecting distance>=0.1.3\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.4->g2p_en) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.4->g2p_en) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.4->g2p_en) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.4->g2p_en) (2022.6.2)\n",
            "Building wheels for collected packages: distance\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16275 sha256=3db0c3b4a761de4e31df9018ec7fa64a210918455dd6d3ffaefdecb5cbcb294f\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/b3/aa/04241cced6d1722b132273b1d6aafba317887ec004f48b853a\n",
            "Successfully built distance\n",
            "Installing collected packages: distance, g2p_en\n",
            "Successfully installed distance-0.1.3 g2p_en-2.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.9/dist-packages (2.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.9/dist-packages (0.8.1)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.22.4)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.4.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.56.4)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.9/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (23.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.7.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.43.0->librosa) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.43.0->librosa) (63.4.3)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (3.1.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.0->librosa) (2.25.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyworld\n",
            "  Downloading pyworld-0.3.2.tar.gz (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.9/dist-packages (from pyworld) (0.29.33)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pyworld) (1.22.4)\n",
            "Building wheels for collected packages: pyworld\n",
            "  Building wheel for pyworld (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyworld: filename=pyworld-0.3.2-cp39-cp39-linux_x86_64.whl size=895527 sha256=9e41efa8d1f364e22eb9bf2c834cf44650f076a44fd1caaec0e0e628456c6cbb\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/91/01/58aa68f1f055ce534049e668292b710500100da0262079b8f5\n",
            "Successfully built pyworld\n",
            "Installing collected packages: pyworld\n",
            "Successfully installed pyworld-0.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tgt\n",
            "  Using cached tgt-1.4.4.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tgt\n",
            "  Building wheel for tgt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tgt: filename=tgt-1.4.4-py3-none-any.whl size=28922 sha256=cbea7d474e5d93d00470d281fd0ce6ada03393a319e9656e63495a16451bb9c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/d4/e5/039c9c6c19848fcc33223ee8da975d73b2da572d25da27bea7\n",
            "Successfully built tgt\n",
            "Installing collected packages: tgt\n",
            "Successfully installed tgt-1.4.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pypinyin==0.39.0\n",
            "  Using cached pypinyin-0.39.0-py2.py3-none-any.whl (780 kB)\n",
            "Installing collected packages: pypinyin\n",
            "Successfully installed pypinyin-0.39.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 KB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.9/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.6.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from gdown) (4.9.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from gdown) (3.9.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.9/dist-packages (from gdown) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->gdown) (2.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (4.0.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.9/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Infer"
      ],
      "metadata": {
        "id": "04WRc1FTPBcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#貌似不行\n",
        "!gdown \"https://drive.google.com/uc?id=1DBRkALpPd6FL9gjHMmMEdHODmkgNIIK4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhuVKFA8NDAT",
        "outputId": "ee7ed11b-3012-4925-8c07-e07451cb7575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access denied with the following error:\n",
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1DBRkALpPd6FL9gjHMmMEdHODmkgNIIK4 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 synthesize.py --text \"大家好\" --speaker_id 1 --restore_step 600000 --mode single -p config/AISHELL3/preprocess.yaml -m config/AISHELL3/model.yaml -t config/AISHELL3/train.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poQqEedhAIpQ",
        "outputId": "6cef7969-cbf2-4133-9752-acf2e30f23f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/FastSpeech2/synthesize.py\", line 188, in <module>\n",
            "    model = get_model(args, configs, device, train=False)\n",
            "  File \"/content/FastSpeech2/utils/model.py\", line 20, in get_model\n",
            "    ckpt = torch.load(ckpt_path)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 771, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 270, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/serialization.py\", line 251, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './output/ckpt/AISHELL3/600000.pth.tar'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train(原版)"
      ],
      "metadata": {
        "id": "7ev_-SYBOg1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 准备数据"
      ],
      "metadata": {
        "id": "v-uvZAt6Pu0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget\n",
        "!pip install tarfile"
      ],
      "metadata": {
        "id": "u9z5om2KQA24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519024ca-28f1-45a4-d539-c5a3cb3a988d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9676 sha256=bfb823a1a3b5092d0355256a771bdd4daf363f5b22ab19ac0eb09ac3080dee0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tarfile (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tarfile\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 下载 LJspeech\n",
        "# 3min\n",
        "%cd /content\n",
        "!wget --no-check-certificate -r http://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2"
      ],
      "metadata": {
        "id": "uqUELCosPK0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c309aba-6a1d-46c1-d3ce-98910bc9d015"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2023-03-17 15:40:47--  http://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "Resolving data.keithito.com (data.keithito.com)... 174.138.79.61\n",
            "Connecting to data.keithito.com (data.keithito.com)|174.138.79.61|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2748572632 (2.6G) [application/octet-stream]\n",
            "Saving to: ‘data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2’\n",
            "\n",
            "data.keithito.com/d 100%[===================>]   2.56G  12.1MB/s    in 3m 23s  \n",
            "\n",
            "2023-03-17 15:44:11 (12.9 MB/s) - ‘data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n",
            "\n",
            "FINISHED --2023-03-17 15:44:11--\n",
            "Total wall clock time: 3m 24s\n",
            "Downloaded: 1 files, 2.6G in 3m 23s (12.9 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 解压\n",
        "# 10min\n",
        "%cd /content/data.keithito.com/data/speech/\n",
        "import tarfile\n",
        "filename = \"LJSpeech-1.1.tar.bz2\"\n",
        "tf = tarfile.open(filename)\n",
        "tf.extractall('/content')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1edOjhmPzAs",
        "outputId": "67efa81c-93e3-4d4f-9c4d-8dc019e702e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data.keithito.com/data/speech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 训练"
      ],
      "metadata": {
        "id": "VWxhLL3sP7v_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 测试日志模块（不用再跑了）\n",
        "%cd /content/FastSpeechPPG/FastSpeech2\n",
        "import logging\n",
        "logging.basicConfig(level=logging.DEBUG #设置日志输出格式\n",
        "      ,filename=\"/content/experiment.log\" #log日志输出的文件位置和文件名\n",
        "      ,format=\"%(asctime)s-%(levelname)s: %(message)s\" #日志输出的格式\n",
        "                      # -8表示占位符，让输出左对齐，输出长度都为8位\n",
        "      ,datefmt=\"%Y-%m-%d %H:%M:%S\"  #时间输出的格式\n",
        "      ,force=True)\n",
        "# test\n",
        "logging.debug(\"debug!\")\n",
        "\n",
        "# 这样用就可以了\n",
        "from debugging import logging_init\n",
        "import logging"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqPnY2pfRU6Z",
        "outputId": "7be09699-50ba-471b-daec-fe5b98b71b6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FastSpeechPPG/FastSpeech2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 预处理，好像是去除文字的大小写和特殊符号。还有对音频处理了一下，看不懂。\n",
        "# 4min\n",
        "%cd /content/FastSpeechPPG/FastSpeech2\n",
        "!python3 prepare_align.py config/LJSpeech/preprocess.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec5FM08kOj18",
        "outputId": "d8e909d3-1066-403e-ee3c-56eaf7321283"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FastSpeechPPG/FastSpeech2\n",
            "13100it [02:34, 84.74it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/FastSpeechPPG/FastSpeech2/prepare_align.py\", line 23, in <module>\n",
            "    main(config)\n",
            "  File \"/content/FastSpeechPPG/FastSpeech2/prepare_align.py\", line 10, in main\n",
            "    ljspeech.prepare_align(config)\n",
            "  File \"/content/FastSpeechPPG/FastSpeech2/preprocessor/ljspeech.py\", line 56, in prepare_align\n",
            "    assert 0\n",
            "AssertionError\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "上传 `LJSpeech.zip` 到路径 `FastSpeech2/preprocessed_data/LJSpeech/TextGrid/` 下，并解压"
      ],
      "metadata": {
        "id": "IR8gWtNMbA-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 解压\n",
        "%cd /content/FastSpeechPPG/FastSpeech2/preprocessed_data/LJSpeech\n",
        "import zipfile\n",
        "import os\n",
        "assert os.path.exists('./LJSpeech.zip')\n",
        "zip_file = zipfile.ZipFile('./LJSpeech.zip')\n",
        "zip_file.extractall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u61DgBhkbQ60",
        "outputId": "c8f67fe2-f305-4841-cb6f-73435b9d556e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FastSpeechPPG/FastSpeech2/preprocessed_data/LJSpeech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/FastSpeechPPG/FastSpeech2\n",
        "# 需要23分钟\n",
        "!python3 preprocess.py config/LJSpeech/preprocess.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BQyszJARpbZ",
        "outputId": "148845a6-8b83-4210-acdc-92c96ecdbfa7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FastSpeechPPG/FastSpeech2\n",
            "Processing Data ...\n",
            "100% 1/1 [21:57<00:00, 1317.37s/it]\n",
            "Computing statistic quantities ...\n",
            "Total time: 23.62337556059461 hours\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train\n",
        "%cd /content/FastSpeechPPG/FastSpeech2\n",
        "!python3 train.py -p config/LJSpeech/preprocess.yaml -m config/LJSpeech/model.yaml -t config/LJSpeech/train.yaml"
      ],
      "metadata": {
        "id": "qIne2dnvTlh1",
        "outputId": "d725c3a9-5491-4e4e-970e-083409a5111f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FastSpeechPPG/FastSpeech2\n",
            "Prepare training ...\n",
            "Number of FastSpeech2 Parameters: 35159361\n",
            "Removing weight norm...\n",
            "2023-03-17 17:00:05.599833: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-17 17:00:06.550118: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-17 17:00:06.550244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-17 17:00:06.550266: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Training:   0% 0/900000 [00:00<?, ?it/s]\n",
            "Epoch 1:   0% 0/197 [00:00<?, ?it/s]\u001b[ATraceback (most recent call last):\n",
            "  File \"/content/FastSpeechPPG/FastSpeech2/train.py\", line 209, in <module>\n",
            "    main(args, configs)\n",
            "  File \"/content/FastSpeechPPG/FastSpeech2/train.py\", line 93, in main\n",
            "    assert 0\n",
            "AssertionError\n",
            "Training:   0% 1/900000 [00:03<805:43:54,  3.22s/it]\n",
            "Epoch 1:   0% 0/197 [00:03<?, ?it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train （我们之后要用的）"
      ],
      "metadata": {
        "id": "Tep8DjqQqeuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 下载 librispeech\n",
        "%cd /content\n",
        "!wget --no-check-certificate -r https://us.openslr.org/resources/12/train-clean-100.tar.gz"
      ],
      "metadata": {
        "id": "ZesKMxfKqdcD",
        "outputId": "9788900c-e0e3-4c87-8e25-124622676c94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2023-03-17 17:42:17--  https://us.openslr.org/resources/12/train-clean-100.tar.gz\n",
            "Resolving us.openslr.org (us.openslr.org)... 46.101.158.64\n",
            "Connecting to us.openslr.org (us.openslr.org)|46.101.158.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6387309499 (5.9G) [application/x-gzip]\n",
            "Saving to: ‘us.openslr.org/resources/12/train-clean-100.tar.gz’\n",
            "\n",
            "us.openslr.org/reso 100%[===================>]   5.95G  12.8MB/s    in 7m 43s  \n",
            "\n",
            "2023-03-17 17:50:01 (13.2 MB/s) - ‘us.openslr.org/resources/12/train-clean-100.tar.gz’ saved [6387309499/6387309499]\n",
            "\n",
            "FINISHED --2023-03-17 17:50:01--\n",
            "Total wall clock time: 7m 44s\n",
            "Downloaded: 1 files, 5.9G in 7m 43s (13.2 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 解压 librispeech\n",
        "%cd /content/us.openslr.org/resources/12\n",
        "import tarfile\n",
        "filename = \"train-clean-100.tar.gz\"\n",
        "tf = tarfile.open(filename)\n",
        "tf.extractall('/content')"
      ],
      "metadata": {
        "id": "9D8ND2qKrNhB",
        "outputId": "5d3bdfd8-a3c7-40cb-f2fb-21550a4645db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/us.openslr.org/resources/12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 预处理，算每个音频的mel\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read\n",
        "import torch\n",
        "import layers\n",
        "\n",
        "def load_wav_to_torch(full_path):\n",
        "    sampling_rate, data = read(full_path)\n",
        "    return torch.FloatTensor(data.astype(np.float32)), sampling_rate\n",
        "\n",
        "def get_mel(self, filename):\n",
        "    sampling_rate, data = read(filename)\n",
        "    audio = torch.FloatTensor(data.astype(np.float32))\n",
        "    sampling_rate = sampling_rate\n",
        "    if sampling_rate != self_sampling_rate:\n",
        "        raise ValueError(\"{} {} SR doesn't match target {} SR\".format(\n",
        "            sampling_rate, self_sampling_rate))\n",
        "    audio_norm = audio / max_wav_value\n",
        "    audio_norm = audio_norm.unsqueeze(0)\n",
        "    audio_norm = torch.autograd.Variable(audio_norm, requires_grad=False)\n",
        "    melspec = self.stft.mel_spectrogram(audio_norm)\n",
        "    melspec = torch.squeeze(melspec, 0)\n",
        "\n",
        "    # 还需要写入规定格式名称的文件\n",
        "    # \"{}-mel-{}.npy\".format(speaker, basename)\n",
        "\n",
        "    return melspec\n",
        "\n",
        "max_wav_value = 32768.0\n",
        "self_sampling_rate = 22050\n",
        "filter_length = 1024\n",
        "hop_length = 256\n",
        "win_length = 1024\n",
        "n_mel_channels = 80\n",
        "mel_fmin = 0.0\n",
        "mel_fmax = 8000.0\n",
        "\n",
        "stft = layers.TacotronSTFT(\n",
        "        filter_length, hop_length, win_length,\n",
        "        n_mel_channels, self_sampling_rate, mel_fmin,\n",
        "        mel_fmax)\n"
      ],
      "metadata": {
        "id": "ALCsxSh4rMj3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}